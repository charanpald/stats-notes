\documentclass{beamer}

\usepackage{beamerthemesplit}
\usepackage[utf8x]{inputenc}
\usepackage{pgf}
\usepackage{default}
\usepackage{url}
\usepackage{subfigure}
\usepackage{algorithmic} 
\usepackage{algorithm} 
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{booktabs}

\usetheme{Singapore}

\input{../include/CsdMacros}
\graphicspath{{./Figures/}}

\title{Statistics and the Analysis of Data\\ Lecture 4: Common Probability Distributions}
\author{Charanpal Dhanjal \\ \texttt{charanpal@gmail.com}} 
\institute{\'{E}cole des Ponts}
\date{26th November 2013}

\begin{document}

\frame{\titlepage}


\begin{frame}{Recap}  
\begin{itemize} 
\item Sample spaces, experiments, events 
\item Independence of events   $P(A \cap B) = P(A)P(B)$
\item Conditional probabilities  $P(A | B) = \frac{P(A \cap B)}{P(B)}$
\item Bayes' Law 
\begin{displaymath}
 P(A | B) = \frac{P(B | A)P(A)}{P(B)}
\end{displaymath}
\end{itemize}
\end{frame}

\begin{frame}{Overview}
\begin{itemize} 
\item Random variables 
\item Probability Distributions
\begin{itemize}
\item Binomial, Bernoulli, Geometric 
\item Poisson, Uniform, Exponential 
\item Gaussian  
\end{itemize}  
\end{itemize}
\end{frame}

\begin{frame}{Random Variables} 
\begin{itemize} 
 \item A more general definition of a random variable is any function $X: \Omega \mapsto \mathbb{R}$ 
 \item Another way of thinking about this is if we write $P(X=1, Y=2)$ this is the same as 
 \begin{displaymath}
  P(\{\omega \in \Omega: X(\omega) = 1, Y(\omega) = 2\}) 
 \end{displaymath}
 \end{itemize}
\end{frame}


\begin{frame}{Continuous Random Variables} 
\begin{itemize} 
 \item $X$ is continuous if the following is true 
\begin{displaymath} 
P(\{\omega: X(\omega) \in A\}) = \int_{A} p(x) dx, 
\end{displaymath}
for some interval $A$, where $p(x)$ is known as the \emph{probability density function} 
\end{itemize}
\end{frame}

\begin{frame}{Probability Distributions} 
\begin{itemize}
\item A \emph{probability distribution} defines a random variable 
\item For a discrete variable we have $p_i = P(\{\omega: X(\omega) = i\})$
\begin{itemize}
\item In addition, $\sum_i p_i  = 1$
\item E.g. for a die $a_i = i$, $i=1,\ldots, 6$ and $p_i = 1/6$
\end{itemize}
\item For continuous variable distribution is defined using $p(x)$
\begin{itemize}
\item The probability across the complete range is 1: 
\begin{displaymath}
P(\{\omega: f(\omega) \in \mathbb{R}\}) = \int_\mathbb{R} p(x) dx = 1
\end{displaymath} 
\end{itemize}
\item From a probabilistic standpoint, two variables with the same distribution are identical 
\end{itemize}
\end{frame}

\begin{frame}{Independence}  
\begin{itemize} 
 \item Two variables $X$ and $Y$ are independent if 
 \begin{displaymath} 
  P(X \in A, Y \in B) = P(X \in A)P(Y \in B) \quad \forall A, B
 \end{displaymath}
\item For $n$ variables $X_1, X_2, \ldots, X_n$ independence is 
 \begin{displaymath} 
  P(X_1 \in A_1, \ldots, X_n \in A_n) = P(X_1 \in A_1) \cdots P(X_n \in A_n)
 \end{displaymath}
 for all $A_1, \ldots, A_n$ 
\end{itemize}
\end{frame}

\begin{frame}{Expectation of Discrete Variable} 
\begin{itemize} 
 \item The \emph{expectation} is the analogue of the mean for probability distributions.
 \item Let $X$ be a random variable with domain $\{a_1, a2, \ldots \}$ and $p_i = P(X = a_i)$ then the expectation is 
 \begin{displaymath} 
  \mathbb{E}[X] = \sum_{i=1}^\infty a_i p_i
 \end{displaymath}
\end{itemize}
\end{frame}

\begin{frame}{Expectation of Continuous Variable} 
\begin{itemize} 
 \item The expectation of a continuous variable $X$ with density $p(x)$ is (assuming the integral exists) 
 \begin{displaymath} 
  \mathbb{E}[X] = \int_{-\infty}^\infty x p(x) dx
 \end{displaymath}
\end{itemize}
\end{frame}

\begin{frame}{Variance and Standard Deviation} 
\begin{itemize} 
 \item If $X^2$ is integrable we say that $X$ is \emph{square integrable} and the variance is defined as follows 
 \begin{displaymath} 
 var(X) = \mathbb{E}[X^2] - (\mathbb{E}[X])^2  
 \end{displaymath}
 \item The standard deviation is $\sqrt{var(X)}$
 \item Note that expectation and variance depend only on the probability distribution 
\end{itemize}
\end{frame}

\begin{frame}{Properties of Expectation} 
\begin{itemize} 
 \item Let $X$ and $Y$ be integrable random functions and $\lambda, \rho \in \mathbb{R}$ be constants
 \begin{itemize}
 \item Linearity: $\mathbb{E}[X + \lambda Y + \rho] = \mathbb{E}[X] +  \lambda \mathbb{E}[Y] + \rho$ 
 \item Positivity: $P(X \geq 0) = 1$ implies $\mathbb{E}[X] \geq 0$ 
 \item If $P(X \leq Y) = 1$ then $\mathbb{E}[X] \leq \mathbb{E}[Y]$
 \end{itemize}
\end{itemize}
 
\end{frame}


\begin{frame}{The Bernoulli Distribution}
\begin{itemize}
 \item A (potentially biased) coin lands on heads with $p$ and tails with probability $1-p$
\item The outcome of the toss follows the \emph{Bernoulli Distribution} 
\item Formally X is a Bernoulli random variable, written $X \sim B(p)$ if 
\begin{itemize}
\item It is 0 with probability $1-p$ 
\item It is 1 with probability $p$ 
\end{itemize} 
\end{itemize}
\end{frame}


\begin{frame}{Exercise: A Lottery Game}  
\begin{itemize} 
\item Consider a game in which you have to choose 3 numbers correctly from 49 
\begin{itemize}
\item The ``correct'' numbers are chosen uniformly randomly 
\end{itemize}
\item Each ticket costs 1 Euro, and the prize money is 10,000 Euros. 
\item If you keep on playing, can you make a profit? What return/loss is there on the ``investment''?
\end{itemize}
\end{frame}

\begin{frame}{The Binomial Distribution} 
\begin{itemize} 
 \item The number of time one expects to win the game follows a \emph{Binomial distribution}  
\item More generally, the number of successes of independent observations of a Bernoulli random variable form a Binomial random variable 
\begin{displaymath} 
 P(X = k) = C^k_n p^k (1-p)^{n-k} \quad \forall k = 0, \ldots, n
\end{displaymath}
for a success probability $p$, number of observations $n$ and number of successes $k$ 
\item This is written as $X \sim B(n, p)$ 
\item In the case $n=1$ we get the Bernoulli disribution 
\item $\sum_k P(X = k) = 1$  
\end{itemize}
\end{frame}

\begin{frame}{Exercise} 
\begin{itemize} 
 \item For the same game, what is the probability of first winning on the 10th day? 
\end{itemize}
\end{frame}

\begin{frame}{Geometric Distribution} 
\begin{itemize} 
 \item The \emph{Geometric distribution} represents the probability of a first success in a series of Bernoulli trials with success probability $p$ and failure probability $1-p$.  
 \begin{displaymath} 
 P(X = k) = p (1-p)^{k-1} \quad \forall k = 0, \ldots, n
\end{displaymath}
\item We use the notation $X \sim \mathcal{G}(p)$
\end{itemize}
\end{frame}

\begin{frame}{Poisson Distribution}  
\begin{itemize} 
 \item The \emph{Poisson Distribution} represents probabilities of events occurring within time interval given they occur at known average rate and independently of last.  
 \item E.g. We know that buses at a particular stop come every 10 minutes. A Poisson distribution can tell us the probability of a bus arriving within a 5 minute interval. 
 \item $k$ is the frequency of occurrence within the interval and $\theta > 0$ is the rate. 
 \begin{displaymath} 
  p_k = P(X = k) = \frac{\theta^k e^{-\theta}}{k!}
 \end{displaymath}
\item We use the notation $X \sim \mathcal{P}(\theta)$
\end{itemize}
\end{frame}

\begin{frame}{Bus Example}  
\begin{itemize} 
 \item We know that buses at a particular stop come at an average rate of once every 10 minutes. What is the probability of a bus arriving within a 5 minute interval assuming arrival events are independent?
 \item $\theta = 0.5$ and $k = 1$ 
 \item $P(X = k) = 0.303$ 
\end{itemize}
\end{frame}

\begin{frame}{Uniform Distribution}  
 \begin{itemize} 
  \item We have already seem the discrete uniform distribution e.g. when rolling a fair die. 
\item Taken to the limit, we have for an interval $[a, b]$ 
\begin{displaymath} 
 p(x) = \frac{1}{b-a}
\end{displaymath}
\item Denoted by $X \sim \mathcal{U}(a, b)$
\item Note that  $X \sim \mathcal{U}(a, b)$ implies $\frac{X - a}{b - a} \sim \mathcal{U}(0, 1)$
\end{itemize}
\end{frame}

\begin{frame}{Exponential Distribution} 
\begin{itemize} 
 \item For the bus example what is probability that two buses arrive 20 minutes apart? 
 \item We can model this type of event using the \emph{Exponential distribution} with notation $X \sim \mathcal{E}(\theta)$
 \begin{displaymath}
  p(x) = \frac{1}{\theta} \left\{ \begin{array}{l l} \exp^{-x/\theta} & x \geq 0 \\ 0 & x < 0 \end{array} \right. 
 \end{displaymath}
  where $\theta$ is a scale parameter. 
\end{itemize}
\end{frame}

\begin{frame}{Exponential Distribution Properties}
\begin{itemize} 
 \item The exponential distribution is memoryless 
 \begin{displaymath}
  P(X > T + s | X > t) = P(X > s)
 \end{displaymath}
\item If $X \sim \mathcal{E}(\theta)$ then $X\theta \sim \mathcal{E}(1)$
\end{itemize}
\end{frame}

\begin{frame}{Normal Distribution}  
 
\end{frame}



\end{document}