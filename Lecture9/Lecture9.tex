
\documentclass{beamer}

\usepackage{beamerthemesplit}
\usepackage[utf8x]{inputenc}
\usepackage{pgf}
\usepackage{default}
\usepackage{url}
\usepackage{subfigure}
\usepackage{algorithmic} 
\usepackage{algorithm} 
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{mathtools}

\usetheme{Singapore}

\input{../include/CsdMacros}
\graphicspath{{./Figures/}}

\title{Statistics and the Analysis of Data\\ Lecture 9: Hypothesis Testing}
\author{Charanpal Dhanjal \\ \texttt{charanpal@gmail.com}} 
\institute{\'{E}cole des Ponts}
\date{28th January 2014}

\begin{document}

\frame{\titlepage}

\begin{frame}{Recap}  
\begin{itemize} 
 \item Confidence interval -  $P(\theta^* \in \hat{\theta}) > 1 - \alpha \quad \forall \theta^* \in \Theta $
 \item Asymptotic Confidence
 \item Confidence in a Normal distribution
\begin{itemize} 
\item Z tables 
\end{itemize}
\end{itemize} 
\end{frame}

\begin{frame}{Overview}
\begin{itemize} 
 \item Given a set of data is inference $Z$ statistically significant?
\end{itemize}
\end{frame}

\begin{frame}{Hypothesis Testing}  
\begin{itemize} 
\item Choice between $H_0: \theta^* \in \Theta_0$ and $H_1: \theta^* \in \Theta \setminus \Theta_0$
\item $H_0$ is \emph{null hypothesis} and $H_1$ is \emph{alternative hypothesis} 
\item Can we reject null hypothesis? 
\item Examples 
\begin{itemize} 
\item Is the defendant innocent or guilty? 
\item Is homoeopathy more than just a placebo? 
\item Do bumper stickers reflect car owner behaviour? 
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Critical Region} 
\begin{itemize} 
 \item The \emph{critical} or \emph{regret region} is subspace of $\mathbb{R}^n$ denoted $R_n$ which contains observations that support null hypothesis 
 \begin{itemize}
 \item Reject $H_0$ if $\{X_1, \ldots, X_n\} \in R_n$ 
 \item Do not reject $H_0$ if $\{X_1, \ldots, X_n\} \notin R_n$ 
 \end{itemize} 
\end{itemize}
\end{frame}

\begin{frame}{Test Sidedness} 
\begin{itemize} 
 \item If region of rejection is on one side of sampling distribution, called \emph{one-tailed test}. 
\begin{itemize}
\item E.g. null hypothesis is $\mu \leq  10$, rejection region is numbers greater than 10
\end{itemize} 
\item If region of rejection is on both sides of sampling distribution,  called \emph{two-tailed test}. 
\begin{itemize}
\item E.g. null hypothesis is $\mu = 10$, alternative hypothesis $\mu > 10$ or $\mu < 10$ 
\end{itemize} 
\end{itemize}
\end{frame}

\begin{frame}{Error Types}  
\begin{itemize} 
 \item \emph{Type I error} occurs when one rejects true null hypothesis 
 \begin{itemize}
 \item \emph{Risk} of type I error 
\begin{displaymath} 
\alpha(R_n) = sup_{\theta^* \in \Theta_0} P(\{X_1, \ldots, X_n\} \in R_n) 
\end{displaymath} 
 \end{itemize} 
 \item\emph{Type II error} occurs when one fails to reject false null hypothesis
  \begin{itemize}
 \item Risk of type II error 
\begin{displaymath} 
\beta(R_n) = sup_{\theta^* \notin \Theta_0} P(\{X_1, \ldots, X_n\} \notin R_n)                             
\end{displaymath}
 \end{itemize} 
 \item Probability of not committing Type II error is  \emph{power} of test
 
\end{itemize}
\end{frame}

\begin{frame}{Test Quality}
\begin{itemize} 
 \item Ideal test has $\alpha(R_n) = \beta(R_n) = 0$
 \item More realistically, fix $\alpha \in (0, 1)$, then test of \emph{level} $\alpha$ has $\alpha(R_n) \leq \alpha$ 
 \item One says $R_n$ has \emph{asymptotic level} $\alpha$ if 
\begin{displaymath} 
\lim_{n \rightarrow \infty} \alpha(R_n) \leq \alpha
\end{displaymath}
\end{itemize} 
\end{frame}

\begin{frame}{$p$-values} 
\begin{itemize} 
 \item Statistical tests $S_n$ can be written 
 \begin{displaymath} 
  R_{n, \alpha} = \{\{x_1, \ldots, x_n\}: S_n(x_1, \ldots, x_n) \geq C_\alpha\}
 \end{displaymath}
  where $C_\alpha \in \mathbb{R}$ is test criterion 
 \item Consider $\sup_{\theta^* \in \Theta_0} P(\{X_1, \ldots, X_n\} \in R_{n, \alpha}) = \alpha$
  \begin{itemize}
  \item $R_{n, \alpha}$ increases as $\alpha$ increases 
  \item Threshold $\alpha^*$ such that $R_{n, \alpha^*}$ contains observations and $R_{n, \alpha}$ with $\alpha < \alpha^*$ do not 
  \item This is $p$-value of $R_{n, \alpha}$ 
  \end{itemize} 
 \item In other words, the $p$-value is smallest $\alpha^*$ for which $R_{n, \alpha^*}$ rejects null hypothesis  
\end{itemize}
\end{frame}


\begin{frame}{Example: Binomial Distribution I}  
\begin{itemize} 
 \item Observations $X_1, \ldots, X_n \sim \mathcal{B}(\theta^*)$ from a coin toss
 \item Null hypothesis $H_0: \theta^* = \theta_0$ and alternative $H_1: \theta^* \neq \theta_0$ with $\theta_0 = 0.1$ 
 \item To estimate $\theta^*$ we use $\bar{X} = \frac{1}{n}\sum_i X_i$ 
\end{itemize} 
\end{frame}

\begin{frame}{Example: Binomial Distribution II} 
\begin{itemize} 
\item Variance of Binomial distribution: $\var(X) = \theta^*(1- \theta^*)$
\item Using central limit theorem 
\begin{displaymath} 
 \frac{\sqrt{n}(\bar{X} - \theta^*)}{\sqrt{\theta^*(1- \theta^*)}} \xrightarrow[n \rightarrow \infty]{\mathcal{L}} \mathcal{N}(0, 1)
\end{displaymath}
\item Therefore we define $T(\bar{X}, \theta) = \frac{\sqrt{n}(\bar{X} - \theta)}{\sqrt{\theta(1- \theta)}}$ and $R_n = \{\{X_1, \ldots, X_n\}: |T(\bar{X}, \theta_0)| > b\}$
\item Normally we fix $\alpha$ and find $\lim_{n \rightarrow \infty} P(|T(\bar{X}, \theta_0)| > b) \leq \alpha$ 
\end{itemize}
\end{frame}

\begin{frame}{Example: Binomial Distribution III} 
\begin{itemize} 
 \item We know that $\lim_{n \rightarrow \infty} P(|T(\bar{X}, \theta_0)| > b) $ is the standard normal distribution
 \begin{itemize}
 \item Can find $b$ 
 \end{itemize} 
 \item Reject $H_0$ if 
 \begin{displaymath} 
 \frac{\sqrt{n}(\bar{X} - \theta)}{\sqrt{\theta(1- \theta)}} > b \Leftrightarrow |\bar{X} - 0.1| < \frac{0.3b}{\sqrt{n}} 
 \end{displaymath}
\item We do not reject $H_0$ if the above is not satisfied 
\end{itemize}
\end{frame}

\begin{frame}{Example 2: Exponential Distribution I}  
\begin{itemize} 
 \item Now we consider a continuous distribution: the exponential distribution. 
\begin{itemize} 
\item $X_1, \ldots, X_N \sim  \mathcal{E}(1/\theta^*)$ 
\end{itemize}
\item Want to test $H_0: \theta^* \geq \theta_0$ against $H_1: \theta^* < \theta_0$ with $\theta_0 = 5$ 
\item Use MLE of $\theta^*$ which is $\bar{X}$ we can show that 
\begin{displaymath} 
 \sqrt{n}(\bar{X} - \theta^*) \xrightarrow[n \rightarrow \infty]{\mathcal{L}} \mathcal{N}(0, \theta^*)^2
\end{displaymath}
\end{itemize}
\end{frame}

\begin{frame}{Example 2: Exponential Distribution II} 
\begin{itemize}
 \item Define 
\begin{displaymath} 
T(\bar{X}, \theta) = \frac{\sqrt{n}(\bar{X} - \theta)}{\theta}
\end{displaymath}
and $R_n = \{(x_1, \ldots, x_n\} : \min_{\theta \geq \theta_0} |T(\bar{X}, \theta) | > b$ 
\item Therefore 
\begin{eqnarray*} 
|T(\bar{X}, \theta) | > b &\Rightarrow& |\theta^{-1} \bar{X} - 1| > bn^{-1/2} \quad \forall \theta \geq \theta_0 \\ 
&\Rightarrow& \bar{X} < \theta_0(1 - bn^{-1/2})  \\ 
\end{eqnarray*}
\end{itemize}
\end{frame}

\begin{frame}{Example 2: Exponential Distribution III} 
\begin{itemize} 
 \item We want to determine $b$ such that 
\begin{displaymath} 
 \lim_{n \rightarrow \infty} \sup_{\theta^* \geq \theta_0}P(\bar{X} < \theta_0(1 - bn^{-1/2})) = \alpha 
\end{displaymath}
\item Note that the above distribution does not depend on $\theta^*$. 
\end{itemize}
\end{frame}

\begin{frame}{Example 2: Exponential Distribution IV} 
\begin{eqnarray*} 
 \sup_{\theta^* \geq \theta_0} P(\bar{X} < \theta_0(1 - bn^{-1/2}))  &=& \sup_{\theta^* \geq \theta_0} P\left(\frac{\bar{X}}{\theta^*} < \frac{\theta_0(1 - bn^{-1/2})}{\theta^*}\right)  \\ 
&=& P\left(\frac{\bar{X}}{\theta^*} < \frac{(1 - bn^{-1/2})}{\theta^*}\right)  \\ 
&=& P\left(\frac{\sqrt{n}(\bar{X} - \theta^*)}{\theta^*} < - b\right)  \\ 
&\xrightarrow[n \rightarrow \infty]{} & P(\xi < -b) \\ 
&=& P(\xi > b) = 1 - P(\xi \leq b),
\end{eqnarray*}
where $\xi \sim \mathcal{N}(0, 1)$. 
\end{frame}

\begin{frame}{Example 2: Exponential Distribution IV} 
\begin{itemize} 
 \item To get a confidence level $b = q^N_{1-\alpha}$ 
\item Therefore reject null hypothesis $H_0: \theta^* \geq \theta_0$ iff $\bar{X} < \theta_0(1 - \frac{q_{1-\alpha}^N}{\sqrt{n}}) $
\end{itemize}

\end{frame}


\begin{frame}{Exercise I} 
We have a set of observations $X_1, \ldots, X_n$ from distribution $P_{\theta^*}$ where $\theta^* \in \mathbb{R}$ and  $P_{\theta^*}$ has the density function 
\begin{displaymath} 
p(\theta^*, x) = \frac{1}{2} \exp^{-|x - \theta^*|}, \quad \forall x \in \mathbb{R} 
\end{displaymath}
\begin{itemize} 
 \item Show that the above is a density function and that the median of the sample is the MLE of $\theta^*$ 
 \item Show that the empirical mean of the sample is consistent estimator and asymptotically Normal for $\theta^*$ 
 \item Suppose that $n$ is large and $X_1, \ldots, X_n$ are iid of density $p$ whose median is $\theta^*$. Given the empirical median is written $\hat{Me}$ show that $2p(\theta^*)\sqrt{n}(\hat{Me} - \theta^*) \xrightarrow[n \rightarrow \infty]{\mathcal{L}} \mathcal{N}(0, 1)$ 
\end{itemize}
\end{frame}

\begin{frame}{Summary}
\begin{itemize} 
 \item Hypothesis testing - choose between null and alternative hypotheses 
  \begin{itemize}
 \item $p$-values 
  \end{itemize}
\end{itemize}
\end{frame}


\end{document}